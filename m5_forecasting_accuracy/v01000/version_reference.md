# Version Reference

## v01000
- Baselineとなるもの
- 少し特徴量エンジニアリングをした。
- まともに学習がうまくいくように、LGBMの評価関数に手を加えた。
    - WRMSEのこと


## v01001
- 少し、LGBMのparameterを調整した。
- baselineよりもスコアがやや下がった。


## v01002
- v01001 でbaseline のスコアを超えなかった。
- validation の日数を28日から90日に増やしてみる。
- model, cv のパラメータをprintするように変更


## v01003
- sell_price に特徴量を追加
- calendar を利用し、翌日、翌々日イベント日フラグを作る。
- そのままでは実行できなくなった。
  - メモリ削減のため、コードのリファクタリングを行う。
  - is release フラグを作って、リリース前のデータを除去
- コードのリファクタリグをした。
  - モデルのパラメータが調整しやすくなった。
  - 処理部分が分離できて可読性が上がった気がする。
- 処理が少し変わって待ったのかスコアが思ったように制御できない。
- コードをきれいにして、モデルの挙動は正しいはずなので特徴量を見なおす。それを次のバージョンとする。
  - model のパラメータは、RMSLE * passion regression でやっていき。


## v01004
- コードをきれいにしたので、次に正しく学習するために特徴量を見直す。
  - modelのパラメータは、RMSLE * passion regression。
- BaseSalesFeatureだけで学習してみる。
  - zero_ratio, zero_countを追加してみた。
- 学習をしてみたら今までで一番安定して学習しているようだった。
  - しかしスコアは低い。
  - モデルが何を予測しているのか気になる
- ここまでを安定版として、更に精度を向上させるため、問題と対策をv01005で行う。

### sell price データに関して
- 全データにおいて、sell_priceが大きく変わることは数回。
- 統計量を用いるほどの情報を含んでいるように思えない。
- v01003で用いた`price_momentum`、つまり先週との変動率のような特徴量を使うのがせいぜいのように思える。
- あとは他のストアとの差額？ストアだと少し遠そうなので地域ごとの相対値を出そう。


## v01005
- これまでのモデルに比べると安定した学習とばらつきの少ない特徴量重要度が見られた。
  - passion, RMSLE, TimeSeriesSplit 3 foldで学習
- しかし、精度はよくないので更に精度を上げるための調査を行う。
- 気になること
  - CVしているモデルはほぼ均等の重みで予測に貢献しているのか。
    - 結果：
      - 重み：{0: 0.12483929977038609, 1: 0.2252741809134553, 2: 0.6733449189917613}
        - 上記の重みでアンサンブルしてもそこまで劇的によくなる気配はない。
      - RMSE：0 fold model: 2.3196, 1 fold model: 2.1861, 2 fold model: 2.1388
    - 直近のモデルが最も重みが大きいことがわかった。
      - 精度も直近のほうがいい。
    - looのRandomSeedCVも検討したほうが良さそう。
    - 直近のデータが最も精度がいいことはわかったがまだ、salesのちいさな値に引きづられている様子を感じる。
      - 学習には重みを付けてもいいかも。
      - 売れている個数が多い商品ほど重く評価されるようにしたい。
  - 予測結果を可視化すると実はあまり予測できていないのではないか。
    - 可視化してみたところ、ある程度予測できているようにみえた。
    - 一方で、**問題点・気づきもあった。**
      - HOBBIESは、周期性が弱く予測しにくそう。
      - ここのitemでみるとランダムウォークしているようにみえるが、dept_id,cat_id,store_id,state_id全体では周期性が見られた。
        - **超重要**つまり、各Groupの内部相対比が変化している可能性が高い。
  - rolling, shift でnullになっているデータは捨てたほうがいいのではないか。
    - 当然捨てたほうがよいだろう。

### v01005でやりたいこと
- [x] rolling, shiftにより、nullになっているデータを捨てる。
- [x] モデルの学習方法をRandomSeedCVに変える。
- [x] RMSLE に重みを適応してみる。
  - 重みはどうするか、、、とりあえずv01000同様に、「過去28日における売上個数０個の日数の割合」にする。
    - ２個以下、とか変えられるようにしてもいいかもしれない。
  - 結果
    - 今のデータにこれを適応してみたがあまりいい結果にならなかった。
    - WRMSE, weighted sample は一旦やらない方向ですすめる。
- [x] LightGBMのカスタム損失関数に関して
    - 現状、RMSLEを外から指定している
    - 調べ物をしていると、結果変数をlog1pし、LGBM標準のRMSEを使用している人も多い。
    - 上記の２つは詳細の挙動が違うように思える。
    - なので、念の為、予測にどれくらい変化が生じるのかLBを通して確かめたい。
    - 結果
      - 比較対象：v01005_0.4880.csv.gz, lightgbm のパラメータにsample_weightを追加, LB:0.69093


### 番外：'metric': 'mape', 'objective': 'mape'　で学習してみた
- 3-fold TimeSeriesSplit
  - RMSE: 3.3881378434386242
  - WRMSSE: 4.245241881112039
- もう少し、mape に合わせて予測変数を調整しないとならない予感
- あと学習が鬼遅い。
- でも、LBとの差はあまりなかったのでその点は優れているかもしれない。


## v01006
- v10005でいろいろ試してバグっぽくなってしまった前の安定版


## v01007
- 安定版のv01006を元に、v01005のように改造していく。
