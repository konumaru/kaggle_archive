# JOIN Competition

## Overview

MCTS(Monte Carlo Tree Search)を用いて、ゲームの最適な手を探索するコンペ。
MCTSには複数のバリアント？があり、ゲームによって最適なバリアントが異なる。

特定のゲームに対し、最適なアルゴリズムを選択できるようにしたい。

今回は特定のゲームに対して特定のMCTSバリアントが相対的にどの程度の性能かを予測する。

MCTSバリアントの得意なゲームの要素を特定することで、新たなアルゴリズムの開発や最適なアルゴリズムの選択に役立てることができる。← これが今回のモデリングのうれしいこと

## Evaluation

2つのエージェントの予測パフォーマンスと実際のパフォーマンスをRMSEで評価する。

2つのエージェントってなんだ？？

## Datasets

- 全部で1.32GBと小さめ
- column数が814とかなり多い
  - ほぼ情報がないカラムも多そう
- 2人用のボードゲームを2つのエージェントがプレイした内容がデータとして与えられる
- 評価用データはAPIで100行ごとのバッチで提供される。全部で60.000行あるっぽい
- `GameRulesetName` は、ゲーム名とルール名の組み合わせ
- `utility_agent1` が今回のターゲットカラム
  - -1.0 ~ 1.0 の値を取る
- `train.csv` と `test.csv` のカラムの差分は、num_wins_agent1, num_draws_agent1,num_losses_agent1,utility_agent1 の有無
- `concept.csv` は、各ゲームの内容に関する情報が入っている
  - ゲーム名もある
  - ゲームのTypeIDなるものも入っている

## What I thought

- 特徴量の数が多くて、boolean、カテゴリカルなものが多そう
- GBDT, NNのアンサンブルは有効そう
- 次元削減はなんとなく効果的ではないと思う（特にGBDTで）
- concept.csv の内容はすでにtrain.csvに含まれているっぽい
- 2つの角度で特徴量を考える必要がありそう
  - どんなエージェントか
  - どんなゲームか
